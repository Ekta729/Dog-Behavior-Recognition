{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT THE FOLLOWING\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATADIR = \"E:/DBR project2\" #GIVE YOUR OWN PATH\n",
    "CATEGORIES = [\"running\" , \"sitting\"] #CHANGE CATEGORIES\n",
    "\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR,category) #joins our path to cat and dog directory\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(img_array , cmap=\"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break\n",
    "\n",
    "print(img_array.shape) #OPTIONAL\n",
    "\n",
    "IMG_SIZE = 100\n",
    "new_array= cv2.resize(img_array , (IMG_SIZE , IMG_SIZE))\n",
    "plt.imshow(new_array , cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "training_data=[]\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR,category) #joins our path to cat and dog directory\n",
    "        class_num= CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                new_array= cv2.resize(img_array , (IMG_SIZE , IMG_SIZE))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()\n",
    "\n",
    "#TO SEE THE LENGHTH OF TRAINING DATA\n",
    "print(len(training_data))\n",
    "\n",
    "#SHUFFLE THE TRAINING DATA\n",
    "import random\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "#FOR CHECKING THE TWO LABELS 0 FOR TONGUE AND 1 FOR CLOSED\n",
    "for sample in training_data[:20]:\n",
    "    print(sample[1])\n",
    "\n",
    "#CREATE TWO PICKLE FILES\n",
    "X = []\n",
    "y = []\n",
    "for features , label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "import pickle\n",
    "\n",
    "pickle_out=open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out=open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "y[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-64-nodes-0-dense-1582527699\n",
      "WARNING:tensorflow:From C:\\Users\\Ekta Gupta\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\Ekta Gupta\\Anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 2997 samples, validate on 333 samples\n",
      "Epoch 1/32\n",
      "2997/2997 [==============================] - 33s 11ms/sample - loss: 0.4878 - acc: 0.7644 - val_loss: 0.3453 - val_acc: 0.8919\n",
      "Epoch 2/32\n",
      "2997/2997 [==============================] - 30s 10ms/sample - loss: 0.3264 - acc: 0.8795 - val_loss: 0.3601 - val_acc: 0.8288\n",
      "Epoch 3/32\n",
      "2997/2997 [==============================] - 30s 10ms/sample - loss: 0.2530 - acc: 0.9022 - val_loss: 0.2557 - val_acc: 0.9189\n",
      "Epoch 4/32\n",
      "2997/2997 [==============================] - 29s 10ms/sample - loss: 0.1896 - acc: 0.9326 - val_loss: 0.1991 - val_acc: 0.9279\n",
      "Epoch 5/32\n",
      "2997/2997 [==============================] - 29s 10ms/sample - loss: 0.1294 - acc: 0.9570 - val_loss: 0.1913 - val_acc: 0.9369\n",
      "Epoch 6/32\n",
      "2997/2997 [==============================] - 32s 11ms/sample - loss: 0.0771 - acc: 0.9783 - val_loss: 0.0985 - val_acc: 0.9670\n",
      "Epoch 7/32\n",
      "2997/2997 [==============================] - 30s 10ms/sample - loss: 0.0472 - acc: 0.9893 - val_loss: 0.0354 - val_acc: 0.9880\n",
      "Epoch 8/32\n",
      "2997/2997 [==============================] - 30s 10ms/sample - loss: 0.0236 - acc: 0.9983 - val_loss: 0.0215 - val_acc: 0.9940\n",
      "Epoch 9/32\n",
      "2997/2997 [==============================] - 30s 10ms/sample - loss: 0.0149 - acc: 0.9990 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 10/32\n",
      "2997/2997 [==============================] - 31s 10ms/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 11/32\n",
      "2997/2997 [==============================] - 30s 10ms/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 12/32\n",
      "2997/2997 [==============================] - 30s 10ms/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 13/32\n",
      "2997/2997 [==============================] - 30s 10ms/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 14/32\n",
      "2997/2997 [==============================] - 30s 10ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 15/32\n",
      "2997/2997 [==============================] - 30s 10ms/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 9.3146e-04 - val_acc: 1.0000\n",
      "Epoch 16/32\n",
      "2997/2997 [==============================] - 32s 11ms/sample - loss: 7.3501e-04 - acc: 1.0000 - val_loss: 8.2206e-04 - val_acc: 1.0000\n",
      "Epoch 17/32\n",
      "2997/2997 [==============================] - 29s 10ms/sample - loss: 5.8155e-04 - acc: 1.0000 - val_loss: 5.2627e-04 - val_acc: 1.0000\n",
      "Epoch 18/32\n",
      "2997/2997 [==============================] - 29s 10ms/sample - loss: 4.9990e-04 - acc: 1.0000 - val_loss: 4.7861e-04 - val_acc: 1.0000\n",
      "Epoch 19/32\n",
      "2997/2997 [==============================] - 31s 10ms/sample - loss: 3.7477e-04 - acc: 1.0000 - val_loss: 4.5987e-04 - val_acc: 1.0000\n",
      "Epoch 20/32\n",
      "2997/2997 [==============================] - 31s 11ms/sample - loss: 2.9186e-04 - acc: 1.0000 - val_loss: 2.8129e-04 - val_acc: 1.0000\n",
      "Epoch 21/32\n",
      "2997/2997 [==============================] - 31s 10ms/sample - loss: 2.4641e-04 - acc: 1.0000 - val_loss: 2.3690e-04 - val_acc: 1.0000\n",
      "Epoch 22/32\n",
      "2997/2997 [==============================] - 48s 16ms/sample - loss: 1.9846e-04 - acc: 1.0000 - val_loss: 1.9120e-04 - val_acc: 1.0000\n",
      "Epoch 23/32\n",
      "2997/2997 [==============================] - 52s 17ms/sample - loss: 1.7279e-04 - acc: 1.0000 - val_loss: 1.7364e-04 - val_acc: 1.0000\n",
      "Epoch 24/32\n",
      "2997/2997 [==============================] - 50s 17ms/sample - loss: 1.2971e-04 - acc: 1.0000 - val_loss: 1.4785e-04 - val_acc: 1.0000\n",
      "Epoch 25/32\n",
      "2997/2997 [==============================] - 54s 18ms/sample - loss: 1.0778e-04 - acc: 1.0000 - val_loss: 1.0688e-04 - val_acc: 1.0000\n",
      "Epoch 26/32\n",
      "2997/2997 [==============================] - 53s 18ms/sample - loss: 8.9539e-05 - acc: 1.0000 - val_loss: 9.5812e-05 - val_acc: 1.0000\n",
      "Epoch 27/32\n",
      "2997/2997 [==============================] - 43s 14ms/sample - loss: 7.2736e-05 - acc: 1.0000 - val_loss: 7.2626e-05 - val_acc: 1.0000\n",
      "Epoch 28/32\n",
      "2997/2997 [==============================] - 45s 15ms/sample - loss: 7.3161e-05 - acc: 1.0000 - val_loss: 7.1286e-05 - val_acc: 1.0000\n",
      "Epoch 29/32\n",
      "2997/2997 [==============================] - 45s 15ms/sample - loss: 5.2199e-05 - acc: 1.0000 - val_loss: 7.3241e-05 - val_acc: 1.0000\n",
      "Epoch 30/32\n",
      "2997/2997 [==============================] - 46s 15ms/sample - loss: 4.1661e-05 - acc: 1.0000 - val_loss: 3.9213e-05 - val_acc: 1.0000\n",
      "Epoch 31/32\n",
      "2997/2997 [==============================] - 47s 16ms/sample - loss: 3.3393e-05 - acc: 1.0000 - val_loss: 3.2677e-05 - val_acc: 1.0000\n",
      "Epoch 32/32\n",
      "2997/2997 [==============================] - 49s 16ms/sample - loss: 2.9297e-05 - acc: 1.0000 - val_loss: 2.9655e-05 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "X= pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y= pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "X=X/255.0\n",
    "\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            model.add(Conv2D(layer_size ,(3,3) , input_shape=X.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "            model.add(Conv2D(conv_layer ,(3,3)))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "            \n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss=\"binary_crossentropy\",\n",
    "                         optimizer=\"adam\",\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X,y,batch_size=10 ,epochs=32, validation_split=0.1)\n",
    "    \n",
    "model.save('64x3-CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    }
   ],
   "source": [
    "#TESTING WITH AN IMAGE THAT IS NOT IN THE DATASET\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"running\" , \"sitting\" ] # will use this to convert prediction num to string value\n",
    "filepath = \"E:/d.jpg\" #GIVE PATH OF YOUR IMAGE\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 100  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # return the image with shaping that TF wants.\n",
    "\n",
    "#SAVE THE MODEL\n",
    "model = tf.keras.models.load_model(\"64x3-CNN.model\")\n",
    "\n",
    "#FOLLOWING WILL GIVE YOU PREDICTION\n",
    "prediction = model.predict([prepare(filepath)])\n",
    "\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
